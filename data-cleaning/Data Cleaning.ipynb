{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    }
   ],
   "source": [
    "# importing pandas module  \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# reading csv file from url  \n",
    "data =pd.read_excel (r'C:\\Python37\\Scripts\\dealmoon-data.xlsx')\n",
    "\n",
    "# Find free shipping and exclusions\n",
    "data[\"Free Shipping\"] = data[\"information\"].str.contains(pat = 'Free shipping', regex = True) \n",
    "data[\"Exclusions Apply\"] = data[\"information\"].str.contains(pat = 'Exclusions Apply', regex = True) \n",
    "\n",
    "  \n",
    "# new data frame with split value columns  by imformation looking for minimun\n",
    "new = data[\"information\"].str.split(r\"Free shipping on | Exclusions\", n = 2, expand = True) \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "data[\"Conditions Free Shipping\"]= new[1] \n",
    "\n",
    "# new data frame with split value columns \n",
    "new = data[\"Conditions Free Shipping\"].str.split(r\".\", n = 2, expand = True) \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "data[\"Conditions Free Shipping\"]= new[0] \n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "new = data[\"Conditions Free Shipping\"].str.split( n = 4, expand = True) \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "data[\"Minimum Free Shipping\"]= new[2] \n",
    "data.drop(columns =[\"Conditions Free Shipping\"], inplace = True) \n",
    "new = data[\"Minimum Free Shipping\"].str.split(r\",|\\(|expires|orders|\\+|code|Fisher-Price|free|shipping|over|with|of|not|Deal|coupon|via|or|Mesh|get\", n = 1, expand = True) \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "data[\"Minimum Free Shipping\"]= new[0] \n",
    "\n",
    "new=data[\"Minimum Free Shipping\"].replace(\"2\", \"$2 items\")\n",
    "data[\"Minimum Free Shipping\"]= new\n",
    "\n",
    "new = data[\"Minimum Free Shipping\"].str.split('ï¼Œ',n = 1, expand = True) \n",
    "\n",
    "# making separate last name column from new data frame \n",
    "data[\"Minimum Free Shipping\"]= new[0] \n",
    "\n",
    "new = data[\"Minimum Free Shipping\"].str.split(\"$\",n = 1, expand = True) \n",
    "data[\"Minimum Free Shipping\"]= new[1] \n",
    "\n",
    "data[\"Minimum Free Shipping\"].fillna(value=pd.np.nan, inplace=True)\n",
    "data[\"Minimum Free Shipping\"].fillna(\"0\", inplace = True)\n",
    "data.loc[data['Free Shipping'] ==False, ['Minimum Free Shipping']] = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "\n",
    "new = data[\"information\"].str.split(r\"code\", n = 1, expand = True) \n",
    "\n",
    "# making separate last name column from new data frame \n",
    "data[\"code\"]= new[1] \n",
    "data.dropna(inplace = False) \n",
    "new = data[\"code\"].str.split(r\"\\n \\n \\\"\", n = 1, expand = True) \n",
    "  \n",
    "# making separate first name column from new data frame \n",
    "data[\"code1\"]= new[0] \n",
    "new = data[\"code1\"].str.split(r\"\\\"\\n \\n\" , n = 1, expand = True) \n",
    "  \n",
    "# making separate first name column from new data frame \n",
    "data[\"code\"]= new[1] \n",
    "data.drop(columns =[\"code1\"], inplace = True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"retailer\"]=data[\"retailer\"].str.lower()\n",
    "data[\"Clothing\"] = data[\"retailer\"].str.contains(pat = r'calvin-klein|adid|hm|lowes|express|gap|hollister|j crew|levis|nike|uniqlo|zara', regex = True) \n",
    "data[\"Superstore\"] = data[\"retailer\"].str.contains(pat = r\"Target|walmart\", regex = True) \n",
    "data[\"Wholesale\"] = data[\"retailer\"].str.contains(pat = r\"costco|sams club\", regex = True) \n",
    "data[\"Department Store\"] = data[\"retailer\"].str.contains(pat = r\"bloomingdales|macys|neiman marcus|nordstrom\", regex = True) \n",
    "data[\"Beauty\"] = data[\"retailer\"].str.contains(pat = r\"sephora\", regex = True) \n",
    "data[\"Electronic\"] = data[\"retailer\"].str.contains(pat = r\"bestbuy\", regex = True) \n",
    "\n",
    "data = pd.melt(data, id_vars=list(data.columns)[:7], value_vars=list(data.columns)[7:],\n",
    "             var_name='Retailer Style', value_name='Dummy')\n",
    "data=data[data.Dummy==True]\n",
    "\n",
    "data.drop(columns=[\"Dummy\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"information\"]=data[\"information\"].str.lower()\n",
    "data[\"Bottoms\"] = data[\"information\"].str.contains(pat = r'jeans|pants|joggers|leggings|short|skirt|sweatpants', regex = True) \n",
    "data[\"Tops\"] = data[\"information\"].str.contains(pat = r'polos|shirts|t-shirts|sweaters|blouses|tanks|hoodies|sweatshirts|tees|bodysuits|tops', regex = True) \n",
    "data[\"Shoes\"] = data[\"information\"].str.contains(pat = r'sneakers|sandals|shoes|high heels|boots|heels|flats|slippers|loafer|flip flops', regex = True) \n",
    "data[\"Outerwear\"] = data[\"information\"].str.contains(pat = r'jackets|coat|outerwear', regex = True) \n",
    "data[\"Underwear\"] = data[\"information\"].str.contains(pat = r'bras|uderwear|panties|panty|socks|boxer', regex = True) \n",
    "data[\"Dresses\"] = data[\"information\"].str.contains(pat = r'dress', regex = True) \n",
    "data[\"Acessories\"] = data[\"information\"].str.contains(pat = r'bracelet|acessor|bags|hat|belt|watch|handbag|wallet|scar|sunglass|jewelry|neck|earing|ring', regex = True) \n",
    "data[\"Acessories\"].value_counts()\n",
    "data[\"TV\"] = data[\"information\"].str.contains(pat = r'tv', regex = True) \n",
    "data[\"Computers\"] = data[\"information\"].str.contains(pat = r'computer|laptop|monitor|deskto|ram|cpu|usb|tablet', regex = True) \n",
    "data[\"Headphones and Speakers\"] = data[\"information\"].str.contains(pat = r'headphones|earbuds|earpods|speaker', regex = True) \n",
    "data[\"Makeup\"] = data[\"information\"].str.contains(pat = r'sephora|makeup|palette', regex = True) \n",
    "data[\"Eyes Makeup\"] = data[\"information\"].str.contains(pat = r'eye|eye|mascara|Masca', regex = True) \n",
    "data[\"Skin Makeup\"] = data[\"information\"].str.contains(pat = r'blushs|bronzer|foundation|Foundation|Blus|Bronz|Primer|primer', regex = True) \n",
    "data[\"Lips\"] = data[\"information\"].str.contains(pat = r'Lips|lip|Balm|balm', regex = True) \n",
    "data[\"Skin Care\"] = data[\"information\"].str.contains(pat = r'moisturizer|Moisturizer|Skin Care|skin care|toner|Skin', regex = True) \n",
    "data[\"Sitewide\"] = data[\"information\"].str.contains(pat = r'sitewide|entire site|entire store|purchase', regex = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(data, id_vars=list(data.columns)[:8], value_vars=list(data.columns)[8:24],\n",
    "             var_name='Product', value_name='Dummy')\n",
    "data=data[data.Dummy==True]\n",
    "data.drop(columns=[\"Dummy\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Week\"]=data['day'].dt.week\n",
    "data[\"year\"]=data['day'].dt.year\n",
    "data[\"promotion\"]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "output=[]          \n",
    "for x in data[\"retailer\"] :\n",
    "     if x not in output:\n",
    "        output.append(x)\n",
    "\n",
    "P=[]\n",
    "for x in data[\"Product\"] :\n",
    "     if x not in P:\n",
    "        P.append(x)\n",
    "\n",
    "for x in output:\n",
    "    data1=data[data.retailer==x]\n",
    "    start=data1['day'].min()\n",
    "    end=data1['day'].max()\n",
    "    df = pd.DataFrame({\"Date\": pd.date_range(start, end)})\n",
    "    df[\"Week\"] = df.Date.dt.weekofyear.astype(int)\n",
    "    df[\"year\"] = df.Date.dt.year.astype(int)\n",
    "    df[\"Control\"]=df[\"Week\"]+df[\"year\"]*100\n",
    "    J=[]\n",
    "    for z in data1[\"Retailer Style\"]:\n",
    "            J=z\n",
    "    for y in P:\n",
    "        data2=data1[data.Product==y]\n",
    "        result = pd.merge(left=df, right=data2, how='left', left_on=['year','Week'], right_on=['year','Week'])\n",
    "        result.drop_duplicates('Control',keep='first',inplace=True)\n",
    "        result.drop(columns =[\"Control\",\"Date\"], inplace = True)\n",
    "        result[\"Product\"]=y\n",
    "        result[\"retailer\"]=x\n",
    "        result[\"Retailer Style\"]=J\n",
    "        result.to_excel( x+y+'.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in output:\n",
    "    dh =pd.read_excel(x+P[0]+'.xlsx')\n",
    "    for y in P[2:16]:\n",
    "        data =pd.read_excel(x+y+'.xlsx')\n",
    "        dh=dh.append(data, ignore_index=True)\n",
    "    dh[\"code\"].fillna(\" \", inplace = True) \n",
    "    dh[\"Free Shipping\"].fillna(0, inplace = True) \n",
    "    dh[\"Minimum Free Shipping\"].fillna(0, inplace = True) \n",
    "    dh[\"promotion\"].fillna(0, inplace = True) \n",
    "    dh.drop(columns =[\"Unnamed: 0\"], inplace = True)\n",
    "    dh.to_excel( x+'_Data.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data =pd.read_excel(output[0]+'_Data.xlsx')\n",
    "data.sort_values(['year', 'Week'], ascending=[False, False])\n",
    "Training , Testing = np.split(data, [int(.75*len(data))])\n",
    "for x in output[1:len(output)]:\n",
    "    data=pd.read_excel(x+'_Data.xlsx') \n",
    "    data.sort_values(['year', 'Week'], ascending=[False, False])\n",
    "    Training2 , Testing2 = np.split(data, [int(.75*len(data))])\n",
    "    Testing=Testing.append(Testing2, ignore_index=True)\n",
    "    Training=Training.append(Training2, ignore_index=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training.drop(columns =[\"information\",\"day\",\"Unnamed: 0\"], inplace = True) \n",
    "Testing.drop(columns =[\"information\",\"day\",\"Unnamed: 0\"], inplace = True) \n",
    "Training.to_excel('Training_complete.xlsx' )\n",
    "Testing.to_excel('Testing_complete.xlsx' )\n",
    "Training.drop(columns =[\"Exclusions Apply\",\"Free Shipping\",\"code\",\"Retailer Style\",\"Minimum Free Shipping\"], inplace = True) \n",
    "Testing.drop(columns =[\"Exclusions Apply\",\"Free Shipping\",\"code\",\"Retailer Style\",\"Minimum Free Shipping\"], inplace = True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = pd.get_dummies(Training)\n",
    "Testing = pd.get_dummies(Testing)\n",
    "Training.to_excel('Training.xlsx' )\n",
    "Testing.to_excel('Testing.xlsx' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
